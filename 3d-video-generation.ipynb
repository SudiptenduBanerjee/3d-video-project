{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5x5OKn0X2Zv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Step 1: Install dependencies\n",
        "!pip install torch torchvision opencv-python-headless numpy timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvW8hT3IYMOh"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8I6TqCYUnJ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Upload video\n",
        "uploaded = files.upload()\n",
        "video_path = list(uploaded.keys())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntgK9_q3YVgX"
      },
      "outputs": [],
      "source": [
        "# Step 3: Extract frames\n",
        "def extract_frames(video_path, output_dir=\"frames\"):\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_paths = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame_path = os.path.join(output_dir, f\"frame_{frame_count:04d}.png\")\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "        frames.append(frame)\n",
        "        frame_paths.append(frame_path)\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    return frames, frame_paths\n",
        "\n",
        "frames, frame_paths = extract_frames(video_path)\n",
        "print(f\"Extracted {len(frames)} frames.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNVSmCKqYWmi"
      },
      "outputs": [],
      "source": [
        "# Step 4: Depth estimation with MiDaS\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\")\n",
        "midas.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas.to(device)\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.small_transform\n",
        "\n",
        "def generate_depth_map(frame_path):\n",
        "    img = cv2.imread(frame_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    input_batch = transform(img).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        prediction = midas(input_batch)\n",
        "        prediction = torch.nn.functional.interpolate(\n",
        "            prediction.unsqueeze(1),\n",
        "            size=img.shape[:2],\n",
        "            mode=\"bicubic\",\n",
        "            align_corners=False,\n",
        "        ).squeeze()\n",
        "\n",
        "    depth_map = prediction.cpu().numpy()\n",
        "    depth_map = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255.0\n",
        "    depth_map = depth_map.astype(np.uint8)\n",
        "    return depth_map\n",
        "\n",
        "depth_maps = [generate_depth_map(frame_path) for frame_path in frame_paths]\n",
        "print(\"Generated depth maps for all frames.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CXJAEinYWj4"
      },
      "outputs": [],
      "source": [
        "# Step 5: Create stereoscopic pairs\n",
        "def create_stereo_pair(frame, depth_map, max_shift=20):\n",
        "    height, width = frame.shape[:2]\n",
        "    left_image = np.zeros_like(frame)\n",
        "    right_image = np.zeros_like(frame)\n",
        "\n",
        "    depth_map = depth_map.astype(np.float32) / 255.0\n",
        "\n",
        "    for y in range(height):\n",
        "        for x in range(width):\n",
        "            shift = int(max_shift * (1 - depth_map[y, x]))\n",
        "            left_x = x + shift\n",
        "            if 0 <= left_x < width:\n",
        "                left_image[y, left_x] = frame[y, x]\n",
        "            right_x = x - shift\n",
        "            if 0 <= right_x < width:\n",
        "                right_image[y, right_x] = frame[y, x]\n",
        "\n",
        "    left_image = cv2.inpaint(left_image, (left_image == 0).all(axis=2).astype(np.uint8), 3, cv2.INPAINT_NS)\n",
        "    right_image = cv2.inpaint(right_image, (right_image == 0).all(axis=2).astype(np.uint8), 3, cv2.INPAINT_NS)\n",
        "\n",
        "    return left_image, right_image\n",
        "\n",
        "stereo_pairs = [create_stereo_pair(frame, depth_map) for frame, depth_map in zip(frames, depth_maps)]\n",
        "print(\"Created stereoscopic pairs for all frames.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdEX1Bf8YWgy"
      },
      "outputs": [],
      "source": [
        "# Step 6: Create anaglyph images\n",
        "def create_anaglyph(left_image, right_image):\n",
        "    anaglyph = np.zeros_like(left_image)\n",
        "    anaglyph[:, :, 0] = left_image[:, :, 0]\n",
        "    anaglyph[:, :, 1] = right_image[:, :, 1]\n",
        "    anaglyph[:, :, 2] = right_image[:, :, 2]\n",
        "    return anaglyph\n",
        "\n",
        "anaglyph_frames = [create_anaglyph(left, right) for left, right in stereo_pairs]\n",
        "print(\"Generated anaglyph frames.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ8U9pYwYWdU"
      },
      "outputs": [],
      "source": [
        "# Step 7: Reconstruct video\n",
        "def create_video(frames, output_path=\"output_3d_video.mp4\", fps=30):\n",
        "    height, width = frames[0].shape[:2]\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    for frame in frames:\n",
        "        out.write(frame)\n",
        "\n",
        "    out.release()\n",
        "    return output_path\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "cap.release()\n",
        "\n",
        "output_video_path = create_video(anaglyph_frames, fps=fps)\n",
        "print(f\"3D video saved as {output_video_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OASIrteXYWZu"
      },
      "outputs": [],
      "source": [
        "# Step 8: Download the output video\n",
        "files.download(output_video_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}